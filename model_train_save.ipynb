{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4748fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from CSV file\n",
    "data = pd.read_csv('Crop_recommendation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef241ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and labels\n",
    "features = data[['N','P','K','temperature','humidity','ph','rainfall']].values\n",
    "labels = data['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input features\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label strings to numeric representations\n",
    "label_to_index = {label: idx for idx, label in enumerate(np.unique(labels))}\n",
    "numeric_labels = np.array([label_to_index[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a532083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to torch.long data type\n",
    "labels = torch.tensor(numeric_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b484f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Split the data into training and test sets while preserving label distribution\n",
    "for train_index, test_index in sss.split(features_normalized, labels):\n",
    "    X_train, X_test = features_normalized[train_index], features_normalized[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to float32 and labels to int64\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = y_train.clone().detach()\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = y_test.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDataset objects\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c15f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ba8b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network architecture with 2 hidden layers\n",
    "class NeuralNetwork2Hidden(nn.Module):\n",
    "    def __init__(self, activation, n_neurons, dropout_rate, weight_init):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(7, n_neurons)\n",
    "        self.bn1 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.bn2 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc3 = nn.Linear(n_neurons, 22)\n",
    "        self.activation = activation()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.weight_init = weight_init\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.weight_init(self.fc1.weight)\n",
    "        self.weight_init(self.fc2.weight)\n",
    "        self.weight_init(self.fc3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define neural network architecture with 5 hidden layers\n",
    "class NeuralNetwork5Hidden(nn.Module):\n",
    "    def __init__(self, activation, n_neurons, dropout_rate, weight_init):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(7, n_neurons)\n",
    "        self.bn1 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.bn2 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc3 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.bn3 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc4 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.bn4 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc5 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.bn5 = nn.BatchNorm1d(n_neurons)\n",
    "        self.fc6 = nn.Linear(n_neurons, 22)\n",
    "        self.activation = activation()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.weight_init = weight_init\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        self.weight_init(self.fc1.weight)\n",
    "        self.weight_init(self.fc2.weight)\n",
    "        self.weight_init(self.fc3.weight)\n",
    "        self.weight_init(self.fc4.weight)\n",
    "        self.weight_init(self.fc5.weight)\n",
    "        self.weight_init(self.fc6.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn4(self.fc4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.bn5(self.fc5(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece14ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function for both models\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                    100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e7e8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for training NeuralNetwork2Hidden\n",
    "activation_2hidden = nn.LeakyReLU\n",
    "n_neurons_2hidden = 40\n",
    "dropout_rate_2hidden = 0.2\n",
    "weight_init_2hidden = nn.init.xavier_normal_\n",
    "optimizer_2hidden = optim.Adamax\n",
    "learning_rate_2hidden = 0.01\n",
    "criterion_2hidden = nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NeuralNetwork2Hidden\n",
    "model_2hidden = NeuralNetwork2Hidden(activation_2hidden, n_neurons_2hidden, dropout_rate_2hidden, weight_init_2hidden)\n",
    "optimizer_2hidden = optimizer_2hidden(model_2hidden.parameters(), lr=learning_rate_2hidden)\n",
    "criterion_2hidden = criterion_2hidden()\n",
    "train_model(model_2hidden, train_loader, optimizer_2hidden, criterion_2hidden, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976db835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for training NeuralNetwork5Hidden\n",
    "activation_5hidden = nn.LeakyReLU\n",
    "n_neurons_5hidden = 40\n",
    "dropout_rate_5hidden = 0.0\n",
    "weight_init_5hidden = nn.init.xavier_normal_\n",
    "optimizer_5hidden = optim.Adam\n",
    "learning_rate_5hidden = 0.01\n",
    "criterion_5hidden = nn.CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd54700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training NeuralNetwork5Hidden\n",
    "model_5hidden = NeuralNetwork5Hidden(activation_5hidden, n_neurons_5hidden, dropout_rate_5hidden, weight_init_5hidden)\n",
    "optimizer_5hidden = optimizer_5hidden(model_5hidden.parameters(), lr=learning_rate_5hidden)\n",
    "criterion_5hidden = criterion_5hidden()\n",
    "train_model(model_5hidden, train_loader, optimizer_5hidden, criterion_5hidden, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e877da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained models to disk\n",
    "torch.save(model_2hidden.state_dict(), 'model_2hidden.pth')\n",
    "torch.save(model_5hidden.state_dict(), 'model_5hidden.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
